{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e837b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not joblib model params found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 3.04542842,\n",
       "       2.01595626])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_layer_sizes, output_size, learning_rate=0.1):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Inicjalizacja wag i biasów dla warstw ukrytych\n",
    "        self.hidden_weights = [np.random.randn(input_size, hidden_layer_sizes[0])]\n",
    "        self.hidden_biases = [np.zeros((1, hidden_layer_sizes[0]))]\n",
    "        for i in range(1, len(hidden_layer_sizes)):\n",
    "            weight = np.random.randn(hidden_layer_sizes[i - 1], hidden_layer_sizes[i])\n",
    "            bias = np.zeros((1, hidden_layer_sizes[i]))\n",
    "            self.hidden_weights.append(weight)\n",
    "            self.hidden_biases.append(bias)\n",
    "\n",
    "        # Inicjalizacja wag i biasów dla warstwy wyjściowej\n",
    "        self.output_weights = np.random.randn(hidden_layer_sizes[-1], output_size)\n",
    "        self.output_bias = np.zeros((1, output_size))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        # Propagacja sygnału w przód\n",
    "        hidden_output = X\n",
    "        self.hidden_outputs = [hidden_output]  # Przechowywanie wyników na warstwach ukrytych\n",
    "        for i in range(len(self.hidden_weights)):\n",
    "            hidden_output = self.sigmoid(np.dot(hidden_output, self.hidden_weights[i]) + self.hidden_biases[i])\n",
    "            self.hidden_outputs.append(hidden_output)\n",
    "        output = self.sigmoid(np.dot(hidden_output, self.output_weights) + self.output_bias)\n",
    "        return output\n",
    "\n",
    "    def backpropagation(self, X, y, output):\n",
    "        # Obliczenie błędu na warstwie wyjściowej\n",
    "        output_error = y - output\n",
    "        output_delta = output_error * self.sigmoid_derivative(output)\n",
    "\n",
    "        # Propagacja wsteczna błędu\n",
    "        hidden_errors = []\n",
    "        hidden_deltas = []\n",
    "        hidden_errors.insert(0, output_delta.dot(self.output_weights.T))\n",
    "        hidden_deltas.insert(0, hidden_errors[0] * self.sigmoid_derivative(self.hidden_outputs[-1]))\n",
    "\n",
    "        for i in range(len(self.hidden_weights) - 1, 0, -1):\n",
    "            hidden_errors.insert(0, hidden_deltas[0].dot(self.hidden_weights[i].T))\n",
    "            hidden_deltas.insert(0, hidden_errors[0] * self.sigmoid_derivative(self.hidden_outputs[i]))\n",
    "\n",
    "        # Aktualizacja wag i biasów\n",
    "        self.output_weights += self.hidden_outputs[-1].T.dot(output_delta) * self.learning_rate\n",
    "        self.output_bias += np.sum(output_delta, axis=0, keepdims=True) * self.learning_rate\n",
    "\n",
    "        for i in range(len(self.hidden_weights)):\n",
    "            self.hidden_weights[i] += self.hidden_outputs[i].T.dot(hidden_deltas[i]) * self.learning_rate\n",
    "            self.hidden_biases[i] += np.sum(hidden_deltas[i], axis=0, keepdims=True) * self.learning_rate\n",
    "\n",
    "    def train(self, X, y, num_epochs=10000):\n",
    "        for epoch in range(num_epochs):\n",
    "            # Propagacja sygnału w przód\n",
    "            output = self.feedforward(X)\n",
    "\n",
    "            # Wsteczna propagacja błędu\n",
    "            self.backpropagation(X, y, output)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                loss = np.mean(np.square(y - output))\n",
    "                print(f\"Epoka: {epoch}, Strata: {loss}\")\n",
    "\n",
    "# Przykładowe użycie\n",
    "input_size = 64\n",
    "hidden_layer_sizes = [200, 300, 300, 200]\n",
    "output_size = 3\n",
    "# nn = NeuralNetwork(input_size, hidden_layer_sizes, output_size)\n",
    "\n",
    "# # Przykładowe dane treningowe\n",
    "# X = np.random.randn(1, input_size)\n",
    "# y = np.random.randn(1, output_size)\n",
    "\n",
    "# # Trenowanie sieci\n",
    "# # nn.train(X, y)\n",
    "import joblib\n",
    "from neuralNetwork import Net\n",
    "\n",
    "dtNet = Net()\n",
    "\n",
    "# dtNet.feedforward()\n",
    "\n",
    "\n",
    "aa = [[0.,    0.,    0.025, 0.,    0.,    0.3,   0.,    0.,    0.,    0.,    0.,    0.1,\n",
    "  0.01,  0.9,   0.025, 0. ,   0. ,   0.01,  0.   , 0. ,   0.1  , 0.1 ,  0.1  , 0.01,\n",
    "  0.025, 0. ,   0. ,   0. ,   0.01 , 0.01 , 0.01,  0. ,   0.01 , 0. ,   0.025, 0.,\n",
    "  0. ,   0. ,   0.  ,  0.,    0.  ,  0. ,   0. ,   0.,    0.  ,  0. ,   0.,    0.,\n",
    "  0. ,   0.  ,  0. ,   0.,    0.  ,  0. ,   0. ,   0.   , 0.03,  0.025, 0.,    0.06,\n",
    "  0.09 , 0. ,   0.  ,  0.03 ]]\n",
    "\n",
    "bb = [[0.   , 0.   , 0.   , 0.   , 0.   , 0.03 , 0.   , 0.06 , 0.   ,\n",
    "       0.   , 0.9  , 0.   , 0.   , 0.01 , 0.   , 0.   , 0.   , 0.   ,\n",
    "       0.01 , 0.   , 0.03 , 0.   , 0.06 , 0.   , 0.   , 0.01 , 0.   ,\n",
    "       0.1  , 0.   , 0.   , 0.01 , 0.   , 0.   , 0.   , 0.   , 0.01 ,\n",
    "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
    "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.025, 0.   , 0.   ,\n",
    "       0.   , 0.   , 0.   , 0.025, 0.   , 0.06 , 0.09 , 0.025, 0.025,\n",
    "       0.03 ]]\n",
    "\n",
    "cc = [[0.   , 0.03 , 0.025, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
    "       0.   , 0.   , 0.   , 0.01 , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
    "       0.   , 0.   , 0.9   , 0.   , 0.   , 0.   , 0.   , 0.025, 0.   ,\n",
    "       0.   , 0.   , 0.   , 0.   , 0.03 , 0.   , 0.   , 0.   , 0.   ,\n",
    "       0.   , 0.  , 0.   , 0.   , 0.025, 0.   , 0.   , 0.   , 0.   ,\n",
    "       0.025, 0.   , 0.025, 0.   , 0.   , 0.   , 0.   , 0.   , 0.025,\n",
    "       0.   , 0.   , 0.03 , 0.   , 0.   , 0.06 , 0.09 , 0.   , 0.   ,\n",
    "       0.03 ]]\n",
    "\n",
    "dd = [[0.3  , 0.2  , 0.2  , 0  , 0  , 0.2  , 0.2  , 0.3  , 0.1  ,\n",
    "       0.1  , 0.1  , 0.1  , 0.1  , 0.1  , 0.1  , 0.1  , 0.   , 0.   ,\n",
    "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
    "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
    "       0.   , 0.   , 0.   , 0.   , 0.9   , 0.   , 0.   , 0.   , 0.   ,\n",
    "       0.   , 0.   , 0.6   , 0.01 , 0.01 , 0.01 , 0.01 , 0.01 , 0.01 ,\n",
    "       0.01 , 0.01 , 0.03 , 0.025, 0.025, 0.06 , 0.09 , 0.025, 0.025,\n",
    "       0.03 ]]\n",
    "li = np.array(dd[0]) / 150\n",
    "# res = 0\n",
    "# for ids, x in enumerate(li):\n",
    "#     idx = ids + 1\n",
    "#     v = (0.000001 * idx) + (x * idx)\n",
    "#     print(f\"idx={idx} x={x} (0.0001 * idx)={(0.000001 * idx)} v={v}\")\n",
    "#     res += v\n",
    "\n",
    "X = np.array(aa)\n",
    "XX = np.array(bb)\n",
    "XXX = np.array(cc)\n",
    "\n",
    "# res\n",
    "\n",
    "dtNet.feedforward(0.3919579999999999), dtNet.feedforward(0.46830799999999995), dtNet.feedforward(0.5017579999999999)\n",
    "# dtNet.hidden_biases\n",
    "\n",
    "# 0.7432000000000002\n",
    "# 0.5902000000000002\n",
    "# 0.25417\n",
    "#0.6697\n",
    "np.random.uniform(0, 0.01)\n",
    "aa = np.zeros(64).reshape(8,8)\n",
    "aa = aa + 2\n",
    "# aa[5][5] = 5\n",
    "# aa = aa.reshape(64)\n",
    "aa\n",
    "\n",
    "a = [0.0416408,  0.49679512, 0.35026553, 0.5171347,  3.04542842, 2.01595626\n",
    "\n",
    "  ]\n",
    "\n",
    "a = np.array(a)\n",
    "# a = np.array(a).tolist()\n",
    "\n",
    "# del a[len(a) - 1]\n",
    "# del a[len(a) - 1]\n",
    "a[a < 1] = 0\n",
    "a\n",
    "# a = 'a3d4f'\n",
    "# # np.round(a,3)\n",
    "# if len(a) == 5 and  not a[4].upper() == 'F':\n",
    "#     print(a[4])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
